{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries you might not have\n",
    "# !python3 -m pip install --upgrade nbconvert \n",
    "# !python3 -m pip install --upgrade nbstripout \n",
    "# !python3 -m pip install tomotopy\n",
    "# !python3 -m pip install sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/dylfox21/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/dylfox21/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "# Things to install from nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import tomotopy as tp\n",
    "from itertools import chain\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import sklearn.preprocessing\n",
    "import imblearn.over_sampling\n",
    "\n",
    "import dataloader\n",
    "import bow\n",
    "import slda\n",
    "import post_classifier\n",
    "import aggregate\n",
    "import user_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 490196/2038753 [00:00<00:00, 2435807.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flagging empty posts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2038753/2038753 [00:00<00:00, 2718683.90it/s]\n",
      "  0%|          | 3274/2038753 [00:00<01:02, 32739.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending Titles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2038753/2038753 [00:43<00:00, 47086.10it/s]\n",
      "  0%|          | 4518/2038753 [00:00<00:45, 45157.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering subset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2038753/2038753 [00:31<00:00, 64403.99it/s]\n",
      "  1%|          | 663/57015 [00:00<00:08, 6620.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57015/57015 [00:09<00:00, 6136.39it/s] \n",
      " 17%|█▋        | 9863/57015 [00:00<00:00, 98627.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57015/57015 [00:00<00:00, 119599.56it/s]\n",
      "  0%|          | 262/57015 [00:00<00:21, 2618.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing sentences into words...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57015/57015 [00:22<00:00, 2542.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22454/22454 [00:00<00:00, 544688.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22454\n",
      "Filtering posts far away from SW posts...\n",
      "9326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Uncomment below to process data if you have not already\n",
    "\n",
    "POSTPATH = './Data/crowd/train/shared_task_posts.csv'\n",
    "LABELPATH = './Data/crowd/train/crowd_train.csv'\n",
    "USERPATH = './Data/crowd/train/task_C_train.posts.csv'\n",
    "\n",
    "users = dataloader.load_user_subset_from_train(USERPATH, subset = 1000)\n",
    "    \n",
    "user_to_post, post_to_words, post_to_metadata = dataloader.load_posts(POSTPATH, user_subset = users, append_title = True)\n",
    "post_to_label = dataloader.load_classification(LABELPATH, user_to_post, post_to_words, post_to_metadata, user_subset = users)\n",
    "filtered_data, sw_posts, sw_timestamps = dataloader.filter_posts(post_to_label, post_to_metadata, filter_images=True)\n",
    "print(len(filtered_data))\n",
    "filtered_data = dataloader.filter_near_SW(filtered_data,post_to_metadata, sw_timestamps)\n",
    "print(len(filtered_data))\n",
    "\n",
    "filtered_data = dataloader.filter_stopwords(filtered_data)\n",
    "sw_posts = dataloader.filter_stopwords(sw_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDERPATH = './Processing/crowd_processed/'\n",
    "dataloader.save_to_folder(FOLDERPATH, user_to_post, post_to_metadata, filtered_data, sw_posts, sw_timestamps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Process Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDERPATH = './Processing/crowd_processed/'\n",
    "user_to_post, post_to_metadata, filtered_data, sw_posts, sw_timestamps = dataloader.load_from_folder(FOLDERPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "258\n",
      "138\n",
      "342\n",
      "1126\n",
      "9326\n"
     ]
    }
   ],
   "source": [
    "print(len([filtered_data[key] for key in filtered_data.keys() if filtered_data[key][2] == 'a']))\n",
    "print(len([filtered_data[key] for key in filtered_data.keys() if filtered_data[key][2] == 'b']))\n",
    "print(len([filtered_data[key] for key in filtered_data.keys() if filtered_data[key][2] == 'c']))\n",
    "print(len([filtered_data[key] for key in filtered_data.keys() if filtered_data[key][2] == 'd']))\n",
    "print(len(filtered_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLDA Model: Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Topic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9326/9326 [00:00<00:00, 49591.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning sLDA training...\n",
      "Iteration: 0\tLog-likelihood: -9.876305861994776\n",
      "Iteration: 100\tLog-likelihood: -9.028368161243135\n",
      "Iteration: 200\tLog-likelihood: -8.913993467189561\n",
      "Iteration: 300\tLog-likelihood: -8.855716400352637\n",
      "Iteration: 400\tLog-likelihood: -8.817655633498278\n",
      "Iteration: 500\tLog-likelihood: -8.789588060180847\n",
      "Iteration: 600\tLog-likelihood: -8.7772845216768\n",
      "Iteration: 700\tLog-likelihood: -8.773521723711754\n",
      "Iteration: 800\tLog-likelihood: -8.77084122340052\n",
      "Iteration: 900\tLog-likelihood: -8.765876076381648\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "model = slda.train_slda_model_from_data(filtered_data, topics=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Model Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Suicidality Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>url, us, min, survey, gt95, person, short, stu...</td>\n",
       "      <td>-4.383256912231445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>person, psn, ps4, add, lvl, vog, looking, hm, ...</td>\n",
       "      <td>-3.6554858684539795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>english, language, person, german, time, nativ...</td>\n",
       "      <td>-3.6365163326263428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>person, god, people, believe, book, church, at...</td>\n",
       "      <td>-3.598055601119995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>person, vs, persons, team, 1, characters, char...</td>\n",
       "      <td>-3.536412000656128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>baby, dog, family, like, husband, puppy, dogs,...</td>\n",
       "      <td>-3.441037654876709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>car, bike, points, city, area, experience, new...</td>\n",
       "      <td>-3.4356982707977295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>person, gt, bra, fit, size, file, bras, list, ...</td>\n",
       "      <td>-3.2810873985290527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>buy, price, sell, person, stock, options, buyi...</td>\n",
       "      <td>-3.2133429050445557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>person, keys, w, h, url, dragon, killed, blue,...</td>\n",
       "      <td>-3.2039291858673096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>use, anyone, problem, phone, using, help, scre...</td>\n",
       "      <td>-3.0851025581359863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>person, poker, player, players, hands, play, 2...</td>\n",
       "      <td>-3.0534493923187256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>time, ive, got, im, get, back, first, last, da...</td>\n",
       "      <td>-3.0145068168640137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>person, amazon, power, build, video, atx, cpu,...</td>\n",
       "      <td>-2.9711837768554688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>post, please, subreddit, thread, reddit, perso...</td>\n",
       "      <td>-2.9371135234832764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>person, damage, 2, use, 1, useful, using, stat...</td>\n",
       "      <td>-2.887779712677002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>site, tank, web, use, key, sites, trust, memes...</td>\n",
       "      <td>-2.8577253818511963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>im, would, help, anyone, like, looking, person...</td>\n",
       "      <td>-2.7365517616271973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>sex, hair, guys, blood, wear, rough, light, po...</td>\n",
       "      <td>-2.7343087196350098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>person, pokemon, iv, 0, offers, set, hidden, o...</td>\n",
       "      <td>-2.7070205211639404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>person, oxycodone, email, mg, cheap, pain, us,...</td>\n",
       "      <td>-2.690247058868408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>night, one, got, back, house, came, room, us, ...</td>\n",
       "      <td>-2.6734378337860107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>build, person, pc, games, parts, computer, nee...</td>\n",
       "      <td>-2.627345085144043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>humble, bundle, person, 2, x, weekly, bundleur...</td>\n",
       "      <td>-2.5234568119049072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>would, person, may, one, us, could, world, fre...</td>\n",
       "      <td>-2.1798582077026367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>person, retail, new, sold, 300, 200, 400, used...</td>\n",
       "      <td>-2.126558303833008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>im, looking, person, pm, know, send, talk, sur...</td>\n",
       "      <td>-2.0951104164123535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>deck, cards, person, mana, decks, card, marath...</td>\n",
       "      <td>-2.0883448123931885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>like, would, dont, think, know, people, get, m...</td>\n",
       "      <td>-1.802871584892273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>person, 2, x, editionurl, 2url, 3, game, dont,...</td>\n",
       "      <td>-1.7832977771759033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>girl, said, girls, like, date, go, talk, shes,...</td>\n",
       "      <td>-1.7072374820709229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>round, gun, pick, rounds, n, 0, pistol, draft,...</td>\n",
       "      <td>-1.6670148372650146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>skin, blade, oil, india, british, use, america...</td>\n",
       "      <td>-1.6371899843215942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>money, would, pay, home, paid, credit, rent, a...</td>\n",
       "      <td>-1.3806432485580444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>weight, eat, im, food, water, eating, fat, ket...</td>\n",
       "      <td>-0.9877682328224182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>’, ”, “, person, –, thc, little, cannabis, man...</td>\n",
       "      <td>-0.8653386235237122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>game, play, games, playing, players, team, pla...</td>\n",
       "      <td>-0.8174912333488464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>song, music, person, songs, show, listen, find...</td>\n",
       "      <td>-0.7586884498596191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>im, work, school, job, year, college, class, w...</td>\n",
       "      <td>-0.48345544934272766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>im, dont, know, like, want, feel, life, really...</td>\n",
       "      <td>2.182051658630371</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Topic Suicidality Coefficient\n",
       "0   url, us, min, survey, gt95, person, short, stu...      -4.383256912231445\n",
       "1   person, psn, ps4, add, lvl, vog, looking, hm, ...     -3.6554858684539795\n",
       "2   english, language, person, german, time, nativ...     -3.6365163326263428\n",
       "3   person, god, people, believe, book, church, at...      -3.598055601119995\n",
       "4   person, vs, persons, team, 1, characters, char...      -3.536412000656128\n",
       "5   baby, dog, family, like, husband, puppy, dogs,...      -3.441037654876709\n",
       "6   car, bike, points, city, area, experience, new...     -3.4356982707977295\n",
       "7   person, gt, bra, fit, size, file, bras, list, ...     -3.2810873985290527\n",
       "8   buy, price, sell, person, stock, options, buyi...     -3.2133429050445557\n",
       "9   person, keys, w, h, url, dragon, killed, blue,...     -3.2039291858673096\n",
       "10  use, anyone, problem, phone, using, help, scre...     -3.0851025581359863\n",
       "11  person, poker, player, players, hands, play, 2...     -3.0534493923187256\n",
       "12  time, ive, got, im, get, back, first, last, da...     -3.0145068168640137\n",
       "13  person, amazon, power, build, video, atx, cpu,...     -2.9711837768554688\n",
       "14  post, please, subreddit, thread, reddit, perso...     -2.9371135234832764\n",
       "15  person, damage, 2, use, 1, useful, using, stat...      -2.887779712677002\n",
       "16  site, tank, web, use, key, sites, trust, memes...     -2.8577253818511963\n",
       "17  im, would, help, anyone, like, looking, person...     -2.7365517616271973\n",
       "18  sex, hair, guys, blood, wear, rough, light, po...     -2.7343087196350098\n",
       "19  person, pokemon, iv, 0, offers, set, hidden, o...     -2.7070205211639404\n",
       "20  person, oxycodone, email, mg, cheap, pain, us,...      -2.690247058868408\n",
       "21  night, one, got, back, house, came, room, us, ...     -2.6734378337860107\n",
       "22  build, person, pc, games, parts, computer, nee...      -2.627345085144043\n",
       "23  humble, bundle, person, 2, x, weekly, bundleur...     -2.5234568119049072\n",
       "24  would, person, may, one, us, could, world, fre...     -2.1798582077026367\n",
       "25  person, retail, new, sold, 300, 200, 400, used...      -2.126558303833008\n",
       "26  im, looking, person, pm, know, send, talk, sur...     -2.0951104164123535\n",
       "27  deck, cards, person, mana, decks, card, marath...     -2.0883448123931885\n",
       "28  like, would, dont, think, know, people, get, m...      -1.802871584892273\n",
       "29  person, 2, x, editionurl, 2url, 3, game, dont,...     -1.7832977771759033\n",
       "30  girl, said, girls, like, date, go, talk, shes,...     -1.7072374820709229\n",
       "31  round, gun, pick, rounds, n, 0, pistol, draft,...     -1.6670148372650146\n",
       "32  skin, blade, oil, india, british, use, america...     -1.6371899843215942\n",
       "33  money, would, pay, home, paid, credit, rent, a...     -1.3806432485580444\n",
       "34  weight, eat, im, food, water, eating, fat, ket...     -0.9877682328224182\n",
       "35  ’, ”, “, person, –, thc, little, cannabis, man...     -0.8653386235237122\n",
       "36  game, play, games, playing, players, team, pla...     -0.8174912333488464\n",
       "37  song, music, person, songs, show, listen, find...     -0.7586884498596191\n",
       "38  im, work, school, job, year, college, class, w...    -0.48345544934272766\n",
       "39  im, dont, know, like, want, feel, life, really...       2.182051658630371"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slda_coefficients = model.get_regression_coef(0)\n",
    "data = []\n",
    "for k in range(model.k):\n",
    "    top_words = model.get_topic_words(k, top_n=40)\n",
    "    words = [word for (word, float) in top_words]\n",
    "    words = \", \".join(words)\n",
    "    data.append([words, slda_coefficients[k]])\n",
    "    \n",
    "indices = np.array(slda_coefficients).argsort()\n",
    "data = np.array(data)\n",
    "data = data[indices]\n",
    "\n",
    "pd.DataFrame(data, columns=[\"Topic\", \"Suicidality Coefficient\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "im, dont, know, like, want, feel, life, really, cant, friends, never, ive, even, get, going, go, much, people, years, way, things, love, one, help, need, always, tell, didnt, friend, time, mom, away, fucking, everything, hate, shit, parents, back, day, said\n"
     ]
    }
   ],
   "source": [
    "# Uncomment to print example of overly negative topic\n",
    "print(data[np.shape(data)[0]-1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sLDA Features: Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/9326 [00:00<05:25, 28.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting topic distributions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9326/9326 [04:08<00:00, 37.53it/s]\n"
     ]
    }
   ],
   "source": [
    "vector_train = slda.get_topic_vecs(model, filtered_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0016523764934390783, 0.0005985179450362921, 0.00014636835840065032, 0.00031015442800708115, 0.0006073200493119657, 0.4037897288799286, 0.03778862580657005, 0.00015629178960807621, 0.08318338543176651, 0.00034016557037830353, 0.0006263265968300402, 0.00044573316699825227, 0.0002578873827587813, 0.0017927708104252815, 0.3473002016544342, 0.000289768329821527, 0.017029784619808197, 0.016991425305604935, 0.00048306502867490053, 0.0002846891002263874, 0.0009299757075496018, 0.00029477986390702426, 0.0007394409039989114, 0.03340107575058937, 0.0015970715321600437, 0.00019966346735600382, 0.017180660739541054, 0.0003156775492243469, 0.0005604436155408621, 0.00046880223089829087, 0.0009860373102128506, 0.00048259063623845577, 0.022451763972640038, 0.0006405130843631923, 0.0001896763133117929, 0.000688247149810195, 0.003109503770247102, 0.00023085711291059852, 0.001312675653025508, 0.00014599169662687927]\n"
     ]
    }
   ],
   "source": [
    "#Uncomment to print example feature vector\n",
    "print(vector_train['hw4uh'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9326/9326 [01:09<00:00, 134.27it/s]\n",
      "100%|██████████| 9326/9326 [01:50<00:00, 84.08it/s]\n"
     ]
    }
   ],
   "source": [
    "word2index,index2word = bow.generate_vocabulary(filtered_data)\n",
    "pca_model, vector_train_bow = bow.get_PCA_vectors_from_post_set(filtered_data, word2index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Classifier: Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post Classifier: Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmax_norm(arr):\n",
    "    \n",
    "    return (arr - np.min(arr))/(np.max(arr) -np.min(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#USE JUST SLDA\n",
    "X_train = np.array([ vector_train[key][0] for key in vector_train.keys()])\n",
    "y_train = np.array([ vector_train[key][1] for key in vector_train.keys()])\n",
    "y_train = y_train.reshape(np.shape(y_train)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "#USE JUST BOW\n",
    "X_train = np.array([ vector_train_bow[key][0] for key in vector_train_bow.keys()])\n",
    "y_train = np.array([ vector_train_bow[key][1] for key in vector_train_bow.keys()])\n",
    "y_train = y_train.reshape(np.shape(y_train)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#USE SLDA + BOW\n",
    "X_train = np.array([ np.concatenate([minmax_norm(vector_train[key][0]),minmax_norm(vector_train_bow[key][0])]) for key in vector_train.keys()])\n",
    "y_train = np.array([ vector_train[key][1] for key in vector_train.keys()])\n",
    "\n",
    "y_train = y_train.reshape(np.shape(y_train)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = imblearn.over_sampling.RandomOverSampler(random_state=0)\n",
    "X_train, y_train = ros.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16400, 80)\n",
      "(16400,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X_train))\n",
    "print(np.shape(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#UNCOMMENT TO RUN GRID SEARCH CV\n",
    "#p_clf = post_classifier.PostClassification(\"LogReg\")\n",
    "#param_dict = {'C':[0.2,0.5,0.7,1,1.5,2,5]}\n",
    "#p_clf.train_grid_search_CV(X_train, y_train, param_dict, groups=5)\n",
    "\n",
    "#RUN WITH OPTIMAL PARAMETERS\n",
    "p_clf = post_classifier.PostClassification(\"LogReg\")\n",
    "p_clf.train(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UNCOMMENT TO RUN GRID SEARCH CV\n",
    "#p_clf = post_classifier.PostClassification(\"LinearSVM\")\n",
    "#param_dict = {'C':[0.2,0.5,1,2]}\n",
    "#p_clf.train_grid_search_CV(X_train, y_train, param_dict, groups=5)\n",
    "\n",
    "p_clf = post_classifier.PostClassification(\"LinearSVM\")\n",
    "p_clf.train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RBF SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UNCOMMENT TO RUN GRID SEARCH CV\n",
    "#p_clf = post_classifier.PostClassification(\"RbfSVM\")\n",
    "#param_dict = {'C':[0.5,1,2,5]}\n",
    "#p_clf.train_grid_search_CV(X_train, y_train, param_dict, groups=5)\n",
    "\n",
    "p_clf = post_classifier.PostClassification(\"RbfSVM\")\n",
    "p_clf.train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_clf = post_classifier.PostClassification(\"AdaBoost\")\n",
    "p_clf.train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_clf = post_classifier.PostClassification(\"RandomForest\")\n",
    "p_clf.train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.63991863\n",
      "Iteration 2, loss = 0.56435977\n",
      "Iteration 3, loss = 0.55365331\n",
      "Iteration 4, loss = 0.54670170\n",
      "Iteration 5, loss = 0.53902474\n",
      "Iteration 6, loss = 0.52865518\n",
      "Iteration 7, loss = 0.51979170\n",
      "Iteration 8, loss = 0.51033889\n",
      "Iteration 9, loss = 0.50233674\n",
      "Iteration 10, loss = 0.49163290\n",
      "Iteration 11, loss = 0.48332509\n",
      "Iteration 12, loss = 0.47641719\n",
      "Iteration 13, loss = 0.46728708\n",
      "Iteration 14, loss = 0.45809468\n",
      "Iteration 15, loss = 0.44866591\n",
      "Iteration 16, loss = 0.44059495\n",
      "Iteration 17, loss = 0.43422832\n",
      "Iteration 18, loss = 0.42844304\n",
      "Iteration 19, loss = 0.42118554\n",
      "Iteration 20, loss = 0.41766574\n",
      "Iteration 21, loss = 0.41726597\n",
      "Iteration 22, loss = 0.40286767\n",
      "Iteration 23, loss = 0.39766109\n",
      "Iteration 24, loss = 0.39342225\n",
      "Iteration 25, loss = 0.38631937\n",
      "Iteration 26, loss = 0.38319653\n",
      "Iteration 27, loss = 0.37670835\n",
      "Iteration 28, loss = 0.37449011\n",
      "Iteration 29, loss = 0.36913125\n",
      "Iteration 30, loss = 0.36810826\n",
      "Iteration 31, loss = 0.36191303\n",
      "Iteration 32, loss = 0.36049353\n",
      "Iteration 33, loss = 0.35457402\n",
      "Iteration 34, loss = 0.35312403\n",
      "Iteration 35, loss = 0.35236550\n",
      "Iteration 36, loss = 0.34229151\n",
      "Iteration 37, loss = 0.34055056\n",
      "Iteration 38, loss = 0.33637809\n",
      "Iteration 39, loss = 0.33279159\n",
      "Iteration 40, loss = 0.32992409\n",
      "Iteration 41, loss = 0.32778668\n",
      "Iteration 42, loss = 0.32355624\n",
      "Iteration 43, loss = 0.32349433\n",
      "Iteration 44, loss = 0.31873791\n",
      "Iteration 45, loss = 0.31469513\n",
      "Iteration 46, loss = 0.31119429\n",
      "Iteration 47, loss = 0.30929860\n",
      "Iteration 48, loss = 0.30508945\n",
      "Iteration 49, loss = 0.30471392\n",
      "Iteration 50, loss = 0.30505662\n",
      "Iteration 51, loss = 0.30317907\n",
      "Iteration 52, loss = 0.29445654\n",
      "Iteration 53, loss = 0.29707479\n",
      "Iteration 54, loss = 0.29075989\n",
      "Iteration 55, loss = 0.28947964\n",
      "Iteration 56, loss = 0.28642373\n",
      "Iteration 57, loss = 0.28062276\n",
      "Iteration 58, loss = 0.28346700\n",
      "Iteration 59, loss = 0.27635313\n",
      "Iteration 60, loss = 0.27521034\n",
      "Iteration 61, loss = 0.27201154\n",
      "Iteration 62, loss = 0.27728045\n",
      "Iteration 63, loss = 0.26875611\n",
      "Iteration 64, loss = 0.27083831\n",
      "Iteration 65, loss = 0.26340378\n",
      "Iteration 66, loss = 0.26074981\n",
      "Iteration 67, loss = 0.25828315\n",
      "Iteration 68, loss = 0.25426008\n",
      "Iteration 69, loss = 0.26258050\n",
      "Iteration 70, loss = 0.25364452\n",
      "Iteration 71, loss = 0.25516970\n",
      "Iteration 72, loss = 0.25779234\n",
      "Iteration 73, loss = 0.24701255\n",
      "Iteration 74, loss = 0.24735269\n",
      "Iteration 75, loss = 0.24297013\n",
      "Iteration 76, loss = 0.24548986\n",
      "Iteration 77, loss = 0.24209806\n",
      "Iteration 78, loss = 0.25094853\n",
      "Iteration 79, loss = 0.24572178\n",
      "Iteration 80, loss = 0.23267888\n",
      "Iteration 81, loss = 0.22834482\n",
      "Iteration 82, loss = 0.23284060\n",
      "Iteration 83, loss = 0.22840678\n",
      "Iteration 84, loss = 0.22716438\n",
      "Iteration 85, loss = 0.23069838\n",
      "Iteration 86, loss = 0.22520820\n",
      "Iteration 87, loss = 0.22645577\n",
      "Iteration 88, loss = 0.21976418\n",
      "Iteration 89, loss = 0.22253700\n",
      "Iteration 90, loss = 0.21925276\n",
      "Iteration 91, loss = 0.23559079\n",
      "Iteration 92, loss = 0.21840240\n",
      "Iteration 93, loss = 0.21658711\n",
      "Iteration 94, loss = 0.21886772\n",
      "Iteration 95, loss = 0.21207664\n",
      "Iteration 96, loss = 0.21625758\n",
      "Iteration 97, loss = 0.20843018\n",
      "Iteration 98, loss = 0.20457463\n",
      "Iteration 99, loss = 0.20648973\n",
      "Iteration 100, loss = 0.21949235\n",
      "Iteration 101, loss = 0.20618844\n",
      "Iteration 102, loss = 0.20738909\n",
      "Iteration 103, loss = 0.20129653\n",
      "Iteration 104, loss = 0.20254596\n",
      "Iteration 105, loss = 0.19558553\n",
      "Iteration 106, loss = 0.19837115\n",
      "Iteration 107, loss = 0.20572886\n",
      "Iteration 108, loss = 0.19910723\n",
      "Iteration 109, loss = 0.19555589\n",
      "Iteration 110, loss = 0.19873825\n",
      "Iteration 111, loss = 0.19733323\n",
      "Iteration 112, loss = 0.19142833\n",
      "Iteration 113, loss = 0.19006237\n",
      "Iteration 114, loss = 0.18954589\n",
      "Iteration 115, loss = 0.18975815\n",
      "Iteration 116, loss = 0.18697621\n",
      "Iteration 117, loss = 0.18537794\n",
      "Iteration 118, loss = 0.18313886\n",
      "Iteration 119, loss = 0.18176624\n",
      "Iteration 120, loss = 0.18353910\n",
      "Iteration 121, loss = 0.18102704\n",
      "Iteration 122, loss = 0.18542820\n",
      "Iteration 123, loss = 0.18789362\n",
      "Iteration 124, loss = 0.18046996\n",
      "Iteration 125, loss = 0.20979051\n",
      "Iteration 126, loss = 0.19034721\n",
      "Iteration 127, loss = 0.17523870\n",
      "Iteration 128, loss = 0.17454182\n",
      "Iteration 129, loss = 0.18002177\n",
      "Iteration 130, loss = 0.17439439\n",
      "Iteration 131, loss = 0.16874128\n",
      "Iteration 132, loss = 0.16816130\n",
      "Iteration 133, loss = 0.16682270\n",
      "Iteration 134, loss = 0.16576617\n",
      "Iteration 135, loss = 0.17331891\n",
      "Iteration 136, loss = 0.17123203\n",
      "Iteration 137, loss = 0.16706412\n",
      "Iteration 138, loss = 0.16809235\n",
      "Iteration 139, loss = 0.17114680\n",
      "Iteration 140, loss = 0.17474874\n",
      "Iteration 141, loss = 0.16825187\n",
      "Iteration 142, loss = 0.16308807\n",
      "Iteration 143, loss = 0.16422246\n",
      "Iteration 144, loss = 0.15918138\n",
      "Iteration 145, loss = 0.16894017\n",
      "Iteration 146, loss = 0.16532954\n",
      "Iteration 147, loss = 0.15955134\n",
      "Iteration 148, loss = 0.16658615\n",
      "Iteration 149, loss = 0.17886395\n",
      "Iteration 150, loss = 0.17420505\n",
      "Iteration 151, loss = 0.15761294\n",
      "Iteration 152, loss = 0.16887029\n",
      "Iteration 153, loss = 0.15746950\n",
      "Iteration 154, loss = 0.15339003\n",
      "Iteration 155, loss = 0.16744804\n",
      "Iteration 156, loss = 0.16309510\n",
      "Iteration 157, loss = 0.15806682\n",
      "Iteration 158, loss = 0.15207165\n",
      "Iteration 159, loss = 0.17169679\n",
      "Iteration 160, loss = 0.15401908\n",
      "Iteration 161, loss = 0.15498644\n",
      "Iteration 162, loss = 0.15093392\n",
      "Iteration 163, loss = 0.15351191\n",
      "Iteration 164, loss = 0.14904452\n",
      "Iteration 165, loss = 0.15338010\n",
      "Iteration 166, loss = 0.15797964\n",
      "Iteration 167, loss = 0.15185206\n",
      "Iteration 168, loss = 0.14943130\n",
      "Iteration 169, loss = 0.14524428\n",
      "Iteration 170, loss = 0.14140932\n",
      "Iteration 171, loss = 0.14946950\n",
      "Iteration 172, loss = 0.14281089\n",
      "Iteration 173, loss = 0.15210663\n",
      "Iteration 174, loss = 0.15195840\n",
      "Iteration 175, loss = 0.14591885\n",
      "Iteration 176, loss = 0.15434907\n",
      "Iteration 177, loss = 0.16058434\n",
      "Iteration 178, loss = 0.15087447\n",
      "Iteration 179, loss = 0.14173927\n",
      "Iteration 180, loss = 0.14697536\n",
      "Iteration 181, loss = 0.15240845\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    }
   ],
   "source": [
    "#UNCOMMENT TO RUN GRID SEARCH CV\n",
    "#p_clf = post_classifier.PostClassification(\"MLP\")\n",
    "#param_dict = {'hidden_layer_sizes':[(64,64),(64,64,64),(32,32), (32,32,32)], 'learning_rate': ('constant', 'adaptive')}\n",
    "#p_clf.train_grid_search_CV(X_train, y_train, param_dict, groups=5)\n",
    "\n",
    "p_clf = post_classifier.PostClassification(\"MLP\")\n",
    "p_clf.train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Post Classifier: Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = p_clf.test(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8107317073170732,\n",
       " 'precision': 0.7859708193041527,\n",
       " 'recall': 0.8540243902439024,\n",
       " 'f1': 0.8185856224430158}"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_clf.get_metrics(y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8910\n",
      "8200\n"
     ]
    }
   ],
   "source": [
    "print(sum(y_pred_train))\n",
    "print(sum(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Classfier: Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate: Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9326/9326 [00:00<00:00, 1587889.87it/s]\n"
     ]
    }
   ],
   "source": [
    "# change y from a, b, c, d, control to -, 1\n",
    "user_to_y_train = defaultdict(int)\n",
    "for data in tqdm.tqdm(filtered_data.keys()):\n",
    "    user_to_y_train[filtered_data[data][0]] = (1 if filtered_data[data][2] == 'd' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_to_uypred_train = defaultdict(list)\n",
    "\n",
    "for i, post_id in enumerate(vector_train.keys()):\n",
    "    user_id = filtered_data[post_id][0]\n",
    "    post_to_uypred_train[post_id] = [user_id, y_pred_train[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved aggreagation of user to post labels...\n"
     ]
    }
   ],
   "source": [
    "user_to_post_label_train = aggregate.aggregate_posts(FOLDERPATH, post_to_uypred_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Argmax: Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_clf_train = user_classifier.UserClassification(user_to_post_label_train)\n",
    "user_to_ypred_train = u_clf_train.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_y_train = []\n",
    "user_y_pred_train = []\n",
    "for user_id in user_to_ypred_train:\n",
    "    user_y_train.append(user_to_y_train[user_id])\n",
    "    user_y_pred_train.append(user_to_ypred_train[user_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7830985915492957,\n",
       " 'precision': 0.46558704453441296,\n",
       " 'recall': 0.8394160583941606,\n",
       " 'f1': 0.5989583333333333}"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_clf_train.get_metrics(user_y_train, user_y_pred_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Data: Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14447/14447 [00:00<00:00, 2112505.57it/s]\n",
      "100%|██████████| 14447/14447 [00:00<00:00, 76060.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flagging empty posts\n",
      "Appending Titles\n",
      "Tokenizing sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 14447/14447 [00:01<00:00, 10042.38it/s]\n",
      "  0%|          | 0/14447 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing...\n",
      "Tokenizing sentences into words...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14447/14447 [00:04<00:00, 3085.06it/s]\n",
      "100%|██████████| 6250/6250 [00:00<00:00, 815377.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249\n",
      "6250\n",
      "Filtering posts far away from SW posts...\n",
      "2145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "POSTPATH2 = './Data/crowd/test/shared_task_posts_test.csv'\n",
    "LABELPATH2 = './Data/crowd/test/crowd_test_C.csv'\n",
    "USERPATH2 = './Data/crowd/test/task_C_test.posts.csv'\n",
    "    \n",
    "user_to_post_test, post_to_words_test, post_to_metadata_test = dataloader.load_posts(POSTPATH2, append_title = True)\n",
    "post_to_label_test = dataloader.load_classification(LABELPATH2, user_to_post_test, post_to_words_test, post_to_metadata_test)\n",
    "filtered_data_test, sw_posts_test, sw_timestamps_test = dataloader.filter_posts(post_to_label_test, post_to_metadata_test, filter_images = True)\n",
    "print(len(filtered_data_test))\n",
    "filtered_data_test = dataloader.filter_near_SW(filtered_data_test, post_to_metadata_test, sw_timestamps_test)\n",
    "print(len(filtered_data_test))\n",
    "\n",
    "filtered_data_test = dataloader.filter_stopwords(filtered_data_test)\n",
    "sw_posts_test = dataloader.filter_stopwords(sw_posts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDERPATH2 = './Processing/crowd_processed_test/'\n",
    "dataloader.save_to_folder(FOLDERPATH2, user_to_post_test, post_to_metadata_test, filtered_data_test, sw_posts_test, sw_timestamps_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Process Data: Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDERPATH2 = './Processing/crowd_processed_test/'\n",
    "user_to_post_test, post_to_metadata_test, filtered_data_test, sw_posts_test, sw_timestamps_test = dataloader.load_from_folder(FOLDERPATH2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1749\n",
      "38\n",
      "140\n",
      "218\n",
      "2145\n"
     ]
    }
   ],
   "source": [
    "print(len([filtered_data_test[key] for key in filtered_data_test.keys() if filtered_data_test[key][2] == 'a']))\n",
    "print(len([filtered_data_test[key] for key in filtered_data_test.keys() if filtered_data_test[key][2] == 'b']))\n",
    "print(len([filtered_data_test[key] for key in filtered_data_test.keys() if filtered_data_test[key][2] == 'c']))\n",
    "print(len([filtered_data_test[key] for key in filtered_data_test.keys() if filtered_data_test[key][2] == 'd']))\n",
    "print(len(filtered_data_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction: Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sLDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2145 [00:00<01:13, 29.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting topic distributions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2145/2145 [00:59<00:00, 35.87it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = slda.vectorize_data_set(model, FOLDERPATH2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2145 [00:00<00:58, 36.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting topic distributions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2145/2145 [00:57<00:00, 37.15it/s]\n"
     ]
    }
   ],
   "source": [
    "vector_test = slda.get_topic_vecs(model, filtered_data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2145/2145 [00:24<00:00, 86.90it/s]\n"
     ]
    }
   ],
   "source": [
    "_, vector_test_bow = bow.get_PCA_vectors_from_post_set(filtered_data_test, word2index, pca_model=pca_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE JUST BOW\n",
    "X_test = np.array([ vector_test_bow[key][0] for key in vector_test_bow.keys()])\n",
    "y_test = np.array([ vector_test_bow[key][1] for key in vector_test_bow.keys()])\n",
    "y_test = y_test.reshape(np.shape(y_test)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "#USE SLDA + BOW\n",
    "X_test = np.array([ np.concatenate([minmax_norm(vector_test[key][0]),minmax_norm(vector_test_bow[key][0])]) for key in vector_test.keys()])\n",
    "y_test = np.array([ vector_test[key][1] for key in vector_test.keys()])\n",
    "\n",
    "y_test = y_test.reshape(np.shape(y_test)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2145, 80)\n",
      "(2145,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X_test))\n",
    "print(np.shape(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Classifier: Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Post Classifier: Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = p_clf.test(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.6638694638694639,\n",
       " 'precision': 0.11485451761102604,\n",
       " 'recall': 0.3440366972477064,\n",
       " 'f1': 0.1722158438576349}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_clf.get_metrics(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "653\n",
      "[218]\n"
     ]
    }
   ],
   "source": [
    "print(sum(y_pred_test))\n",
    "print(sum(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Classifier: Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate: Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2145/2145 [00:00<00:00, 1607429.35it/s]\n"
     ]
    }
   ],
   "source": [
    "# change y from a, b, c, d, control to -, 1\n",
    "user_to_y_test = defaultdict(int)\n",
    "for data in tqdm.tqdm(filtered_data_test.keys()):\n",
    "    user_to_y_test[filtered_data_test[data][0]] = (1 if filtered_data_test[data][2] == 'd' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2145"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2145"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vector_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_to_uypred_test = defaultdict(list)\n",
    "\n",
    "for i, post_id in enumerate(vector_test.keys()):\n",
    "    user_id = filtered_data_test[post_id][0]\n",
    "    post_to_uypred_test[post_id] = [user_id, y_pred_test[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved aggreagation of user to post labels...\n"
     ]
    }
   ],
   "source": [
    "user_to_post_label_test = aggregate.aggregate_posts(FOLDERPATH2, post_to_uypred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Argmax: Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_clf_test = user_classifier.UserClassification(user_to_post_label_test)\n",
    "user_to_ypred_test = u_clf_test.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_y_test = []\n",
    "user_y_pred_test = []\n",
    "for user_id in user_to_ypred_test:\n",
    "    user_y_test.append(user_to_y_test[user_id])\n",
    "    user_y_pred_test.append(user_to_ypred_test[user_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7272727272727273,\n",
       " 'precision': 0.3111111111111111,\n",
       " 'recall': 0.45161290322580644,\n",
       " 'f1': 0.3684210526315789}"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_clf_test.get_metrics(user_y_test, user_y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threshold: Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_clf_test = user_classifier.UserClassification(user_to_post_label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percent:  [0.5  0.51 0.52 0.53 0.54 0.55 0.56 0.57 0.58 0.59 0.6  0.61 0.62 0.63\n",
      " 0.64 0.65 0.66 0.67 0.68 0.69 0.7  0.71 0.72 0.73 0.74 0.75 0.76 0.77\n",
      " 0.78 0.79 0.8  0.81 0.82 0.83 0.84 0.85 0.86 0.87 0.88 0.89 0.9  0.91\n",
      " 0.92 0.93 0.94 0.95 0.96 0.97 0.98 0.99 1.  ]\n",
      "f_score:  [0.38235294117647056, 0.38235294117647056, 0.38235294117647056, 0.38235294117647056, 0.3880597014925373, 0.393939393939394, 0.36923076923076925, 0.36923076923076925, 0.38095238095238093, 0.38095238095238093, 0.36666666666666664, 0.36666666666666664, 0.36666666666666664, 0.3728813559322034, 0.3728813559322034, 0.3728813559322034, 0.3728813559322034, 0.3636363636363636, 0.3636363636363636, 0.3636363636363636, 0.3636363636363636, 0.37037037037037035, 0.37037037037037035, 0.37037037037037035, 0.3773584905660377, 0.39215686274509803, 0.39215686274509803, 0.39215686274509803, 0.39215686274509803, 0.39215686274509803, 0.36, 0.36, 0.36, 0.36, 0.36, 0.36, 0.36, 0.36, 0.3673469387755102, 0.3673469387755102, 0.3673469387755102, 0.3673469387755102, 0.3673469387755102, 0.3673469387755102, 0.3673469387755102, 0.3673469387755102, 0.3673469387755102, 0.3673469387755102, 0.3673469387755102, 0.3673469387755102, 0.0]\n",
      "max:  0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dylfox21/miniconda2/envs/cmsc773/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7727272727272727,\n",
       " 'precision': 0.37142857142857144,\n",
       " 'recall': 0.41935483870967744,\n",
       " 'f1': 0.393939393939394}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_clf_test.find_threshold(user_to_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_to_ypred_test = u_clf_test.minimum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_y_test = []\n",
    "user_y_pred_test = []\n",
    "for user_id in user_to_ypred_test:\n",
    "    user_y_test.append(user_to_y_test[user_id])\n",
    "    user_y_pred_test.append(user_to_ypred_test[user_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.26136363636363635,\n",
       " 'precision': 0.17647058823529413,\n",
       " 'recall': 0.8709677419354839,\n",
       " 'f1': 0.29347826086956524}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_clf_test.get_metrics(user_y_test, user_y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CMSC773",
   "language": "python",
   "name": "cmsc773"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
